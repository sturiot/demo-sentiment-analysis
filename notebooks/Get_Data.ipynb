{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and build dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wget\n",
    "import time\n",
    "import tarfile\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Set the necessary general variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "data_path = root_path + '/data/'\n",
    "raw_data_path = data_path + \"01_raw/\"\n",
    "init_dataset_path = data_path + \"02_intermediate/\"\n",
    "download_output = raw_data_path + \"/aclImdb_v1.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"file://\" + init_dataset_path + \"train.csv\"\n",
    "test_path = \"file://\" + init_dataset_path + \"test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Dowload and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\HOMEWARE\\\\Project\\\\ML\\\\demo-sentiment-analysis\\\\demo-sentiment-analysis/data/01_raw//aclImdb_v1.tar (1).gz'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download(url, download_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_dataset(data_file, output_folder):\n",
    "    tic = time.time()\n",
    "    tar = tarfile.open(data_file)\n",
    "    tar.extractall(path=output_folder)\n",
    "    tar.close()\n",
    "    toc = time.time()\n",
    "    print(toc - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.8723485469818\n"
     ]
    }
   ],
   "source": [
    "decompress_dataset(download_output, raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Process raw data to build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(path, CLASSES):\n",
    "    texts, labels = [], []\n",
    "    for idx, label in enumerate(CLASSES):\n",
    "        for fname in (path / label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load process and store dataset as train and test.csv files\n",
    "def extract_transform_load_dataset(raw_data_path, output_path, timeit=True):\n",
    "    tic = time.time()\n",
    "\n",
    "    BOS = 'xbos'\n",
    "    FLD = 'xfld'\n",
    "    CLASSES = ['neg', 'pos', 'unsup']\n",
    "    col_names = ['sentiment', 'review']\n",
    "    np.random.seed(42)\n",
    "\n",
    "    PATH = Path(raw_data_path + 'aclImdb/')\n",
    "    CLAS_PATH = Path(output_path)\n",
    "\n",
    "    print(PATH)\n",
    "    trn_texts, trn_labels = get_texts(PATH / 'train', CLASSES)\n",
    "    print(len(trn_texts))\n",
    "    print(len(trn_labels))\n",
    "    df_trn = pd.DataFrame({'review': trn_texts, 'sentiment': trn_labels}, columns=col_names)\n",
    "    df_trn[df_trn['sentiment'] !=2].to_csv(CLAS_PATH / 'train.csv', index=False)\n",
    "\n",
    "    val_texts, val_labels = get_texts(PATH / 'test', CLASSES)\n",
    "    df_val = pd.DataFrame({'review': val_texts, 'sentiment': val_labels}, columns=col_names)\n",
    "    df_val.to_csv(CLAS_PATH / 'test.csv', index=False) \n",
    "\n",
    "    (CLAS_PATH / 'classes.txt').open('w', encoding='utf-8').writelines(f'{o}\\n' for o in CLASSES)\n",
    "\n",
    "    toc = time.time()\n",
    "    print(np.round(toc - tic, 2), 'sec')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\HOMEWARE\\Project\\ML\\demo-sentiment-analysis\\demo-sentiment-analysis\\data\\01_raw\\aclImdb\n",
      "75000\n",
      "75000\n",
      "1049.65 sec\n"
     ]
    }
   ],
   "source": [
    "extract_transform_load_dataset(raw_data_path, init_dataset_path, timeit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path, sample=5000):\n",
    "    tic = time.time()\n",
    "\n",
    "    train_dataset = pd.read_csv(train_path).sample(n=sample)\n",
    "\n",
    "    print(train_dataset.haed())\n",
    "\n",
    "    train_reviews = np.array(train_dataset['review'])\n",
    "    train_sentiments = np.array(train_dataset['sentiment'])\n",
    "\n",
    "    test_dataset = pd.read_csv(test_path).sample(n=sample)\n",
    "    test_reviews = np.array(test_dataset['review'])\n",
    "    test_sentiments = np.array(test_dataset['sentiment'])\n",
    "\n",
    "    return train_dataset, test_dataset, train_sentiments, test_sentiments, train_reviews, test_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Store dataset in HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.typs import *\n",
    "from pyspark.sql.context import SQLContext\n",
    "\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return DateType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo - equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StrucField(string, typo)\n",
    "\n",
    "def pandas_to_spark(pandas_df):\n",
    "    column = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types):\n",
    "        struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return spark.createDataFrame(pandas_df, p_schema)\n",
    "\n",
    "def save_csv(pandas_df, path):\n",
    "    df = pandas_to_spark(pandas_df)\n",
    "    df.coalesce(1).write.csv(path = path, header=\"true\", mode=\"overwrite\", sep=\",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handson_k8s",
   "language": "python",
   "name": "azureuser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
